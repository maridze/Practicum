{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Деление-на-выборки-и-векторизация-слов\" data-toc-modified-id=\"Деление-на-выборки-и-векторизация-слов-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Деление на выборки и векторизация слов</a></span></li><li><span><a href=\"#Подбор-гиперпараметров-SVM\" data-toc-modified-id=\"Подбор-гиперпараметров-SVM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Подбор гиперпараметров SVM</a></span></li><li><span><a href=\"#Подбор-гиперпараметров-LogReg\" data-toc-modified-id=\"Подбор-гиперпараметров-LogReg-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Подбор гиперпараметров LogReg</a></span></li><li><span><a href=\"#SVM-на-тесте\" data-toc-modified-id=\"SVM-на-тесте-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>SVM на тесте</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/datasets/toxic_comments.csv\", index_col=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].map(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he matches this background colour im seem...      0\n",
       "2  hey man im really not trying to edit war its j...      0\n",
       "3  more i cant make any real suggestions on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemm_text = \" \".join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7144d45bf04bc4990bd3974f6d92d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data['lemm_text'] = data['text'].progress_apply(lemmatize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** В ходе подготовки датасета твиты были очищены и лемматизированы. При лемматизации я использовал tqdm для того чтобы отслеживать процесс в реальном времени."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деление на выборки и векторизация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data['text']\n",
    "target=data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target,\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words = stopwords)\n",
    "X_train = count_tf_idf.fit_transform(X_train)\n",
    "X_test = count_tf_idf.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", svc),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    \"clf__C\": list(range(1,15,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(\n",
    "    pipeline, \n",
    "    parameter_grid,  \n",
    "    cv=3, \n",
    "    refit = True, \n",
    "    verbose=1, \n",
    "    scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        LinearSVC(random_state=0, tol=1e-05))]),\n",
       "             param_grid={'clf__C': [1, 4, 7, 10, 13]}, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7823631316984551"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= LogisticRegression(solver='liblinear', max_iter=200, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={\n",
    "    'clf__penalty':['l1','l2'],\n",
    "    'clf__C':list(range(1,15,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", lr),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_lr = GridSearchCV(pipeline_lr,\n",
    "                          param_grid,\n",
    "                          n_jobs=-1,\n",
    "                          cv=3,\n",
    "                          scoring='f1',\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           max_iter=200,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__C': [1, 4, 7, 10, 13],\n",
       "                         'clf__penalty': ['l1', 'l2']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7767874058022334"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 4, 'clf__penalty': 'l1'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grid_search_lr.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_final = Pipeline(\n",
    "    [\n",
    "        (\"vect\", TfidfVectorizer()),\n",
    "        (\"clf\", LinearSVC(random_state=0, tol=1e-5, C=1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7860105059441528"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_final.fit(X_train, y_train)\n",
    "pred = pipeline_final.predict(X_test)\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе данного проекта я анализировал отзывы на токсичность. Для этого использовалась tf_idf модель представления языка.\n",
    "1. Сначала я очистил и лемматизировал изначальный текст.\n",
    "2. Затем я поделил датасет на трейн и тес, используя аргумент stratify для сохранения распредления токсичных отзывов.\n",
    "2. Далее я изучил гиперпараметры для двух моделей.\n",
    "\n",
    "LinearSVC дал лучшие результаты на кросс-валидации. На тесте LinearSVC значение **f1 = 0.786**, что является приемлимым результатом в рамках этого проекта"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1717,
    "start_time": "2023-02-27T09:55:53.314Z"
   },
   {
    "duration": 166,
    "start_time": "2023-02-27T09:56:19.252Z"
   },
   {
    "duration": 3540,
    "start_time": "2023-02-27T09:56:35.314Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-27T09:56:41.679Z"
   },
   {
    "duration": 871,
    "start_time": "2023-02-27T09:58:03.454Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T09:58:04.326Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-27T10:03:37.231Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-27T10:04:30.325Z"
   },
   {
    "duration": 2855,
    "start_time": "2023-02-27T10:04:38.532Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-27T10:04:46.808Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:05:07.587Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:13:25.053Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T10:14:53.118Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-27T10:15:09.585Z"
   },
   {
    "duration": 700,
    "start_time": "2023-02-27T10:18:13.765Z"
   },
   {
    "duration": 1397,
    "start_time": "2023-02-27T10:18:18.375Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-27T10:19:19.930Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:19:37.986Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-27T10:20:56.954Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T10:21:28.853Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T10:21:57.880Z"
   },
   {
    "duration": 884,
    "start_time": "2023-02-27T10:22:07.838Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-27T10:22:08.724Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-27T10:22:08.739Z"
   },
   {
    "duration": 2666,
    "start_time": "2023-02-27T10:22:09.681Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-27T10:22:14.978Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T10:22:16.483Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-27T10:23:18.297Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:23:40.456Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T10:23:45.484Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T10:24:29.496Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:24:31.058Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T10:25:53.081Z"
   },
   {
    "duration": 137274,
    "start_time": "2023-02-27T10:26:16.902Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-27T10:28:34.178Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T10:28:37.594Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:29:13.288Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T10:30:31.134Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:30:47.020Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:30:58.964Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-27T10:31:39.342Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:32:52.272Z"
   },
   {
    "duration": 2217,
    "start_time": "2023-02-27T10:33:04.108Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:33:12.627Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T10:33:55.782Z"
   },
   {
    "duration": 1880,
    "start_time": "2023-02-27T10:34:02.165Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T10:34:04.047Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:34:10.407Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T10:34:41.919Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-27T10:58:32.679Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T10:58:33.793Z"
   },
   {
    "duration": 951,
    "start_time": "2023-02-27T10:58:35.695Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-27T10:58:36.648Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-27T10:58:36.684Z"
   },
   {
    "duration": 3360,
    "start_time": "2023-02-27T10:58:36.885Z"
   },
   {
    "duration": 28,
    "start_time": "2023-02-27T10:58:40.247Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T11:08:13.228Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T11:08:21.484Z"
   },
   {
    "duration": 54,
    "start_time": "2023-02-27T11:10:10.914Z"
   },
   {
    "duration": 151,
    "start_time": "2023-02-27T11:10:15.751Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-27T11:10:27.375Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-27T11:10:36.705Z"
   },
   {
    "duration": 70,
    "start_time": "2023-02-27T11:10:52.674Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-27T11:10:58.170Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T11:12:25.873Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T11:13:06.155Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-27T13:23:47.702Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T13:32:05.901Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-27T13:32:06.900Z"
   },
   {
    "duration": 984,
    "start_time": "2023-02-27T13:32:12.520Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-27T13:32:13.514Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-27T13:32:15.819Z"
   },
   {
    "duration": 3511,
    "start_time": "2023-02-27T13:32:18.198Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-27T13:32:26.025Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T13:32:26.330Z"
   },
   {
    "duration": 1452497,
    "start_time": "2023-02-27T13:32:29.470Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T13:56:45.980Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T13:56:46.887Z"
   },
   {
    "duration": 90,
    "start_time": "2023-02-27T13:56:55.175Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-27T13:56:57.179Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-27T13:57:20.625Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T13:57:33.738Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-27T13:58:28.167Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T13:58:59.274Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-27T13:59:02.388Z"
   },
   {
    "duration": 6987,
    "start_time": "2023-02-27T13:59:07.624Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:01:17.076Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:02:21.844Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:03:29.381Z"
   },
   {
    "duration": 362276,
    "start_time": "2023-02-27T14:03:52.962Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-27T14:11:07.704Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:11:24.189Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:12:52.093Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:13:40.883Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:14:14.437Z"
   },
   {
    "duration": 1183,
    "start_time": "2023-02-27T14:15:47.256Z"
   },
   {
    "duration": 2065,
    "start_time": "2023-02-27T14:16:26.554Z"
   },
   {
    "duration": 2065,
    "start_time": "2023-02-27T14:16:39.353Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:21:30.409Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:21:30.703Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:21:31.100Z"
   },
   {
    "duration": 31,
    "start_time": "2023-02-27T14:21:41.953Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:21:57.925Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:23:14.618Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:23:14.960Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:23:15.358Z"
   },
   {
    "duration": 32568,
    "start_time": "2023-02-27T14:23:15.838Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:23:54.496Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:23:54.752Z"
   },
   {
    "duration": 31201,
    "start_time": "2023-02-27T14:23:54.950Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:24:47.123Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:25:00.651Z"
   },
   {
    "duration": 31994,
    "start_time": "2023-02-27T14:25:00.796Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:25:34.750Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:25:35.522Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:25:49.494Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:26:07.010Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:26:07.372Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-27T14:26:13.355Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-27T14:26:13.565Z"
   },
   {
    "duration": 37634,
    "start_time": "2023-02-27T14:26:13.974Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-27T14:26:51.610Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-27T14:26:51.616Z"
   },
   {
    "duration": 1237,
    "start_time": "2023-02-27T14:30:44.529Z"
   },
   {
    "duration": 1239,
    "start_time": "2023-02-27T14:30:50.975Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-27T14:35:03.738Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-27T14:36:35.990Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-27T14:36:46.785Z"
   },
   {
    "duration": 19,
    "start_time": "2023-02-27T14:37:01.064Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-27T14:37:09.785Z"
   },
   {
    "duration": 53,
    "start_time": "2023-02-27T20:59:41.788Z"
   },
   {
    "duration": 1860,
    "start_time": "2023-02-28T11:37:01.345Z"
   },
   {
    "duration": 606,
    "start_time": "2023-02-28T11:37:04.889Z"
   },
   {
    "duration": 2624,
    "start_time": "2023-02-28T11:37:06.379Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-28T11:37:09.006Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-28T11:37:09.021Z"
   },
   {
    "duration": 2452,
    "start_time": "2023-02-28T11:37:10.064Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-28T11:37:13.017Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-28T11:37:13.724Z"
   },
   {
    "duration": 51,
    "start_time": "2023-02-28T11:38:12.848Z"
   },
   {
    "duration": 221,
    "start_time": "2023-02-28T11:38:23.281Z"
   },
   {
    "duration": 147,
    "start_time": "2023-02-28T11:38:28.997Z"
   },
   {
    "duration": 1261879,
    "start_time": "2023-02-28T11:38:40.741Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:02:34.129Z"
   },
   {
    "duration": 69,
    "start_time": "2023-02-28T12:02:34.906Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-28T12:09:01.916Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-28T12:09:55.315Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:09:58.543Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:09:59.989Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:10:00.510Z"
   },
   {
    "duration": 77,
    "start_time": "2023-02-28T12:11:26.584Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:11:40.523Z"
   },
   {
    "duration": 74,
    "start_time": "2023-02-28T12:11:40.527Z"
   },
   {
    "duration": 80,
    "start_time": "2023-02-28T12:12:04.552Z"
   },
   {
    "duration": 120,
    "start_time": "2023-02-28T12:13:55.761Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-28T12:15:10.935Z"
   },
   {
    "duration": 171,
    "start_time": "2023-02-28T12:15:11.205Z"
   },
   {
    "duration": 78,
    "start_time": "2023-02-28T12:15:28.092Z"
   },
   {
    "duration": 101,
    "start_time": "2023-02-28T12:16:12.992Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:17:05.504Z"
   },
   {
    "duration": 144836,
    "start_time": "2023-02-28T12:17:17.749Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:19:51.130Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:19:53.259Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:22:54.878Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-28T12:23:01.230Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:23:04.557Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:23:05.416Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:23:05.595Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:23:34.046Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-28T12:23:37.126Z"
   },
   {
    "duration": 649980,
    "start_time": "2023-02-28T12:23:41.343Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-28T12:35:28.857Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:35:33.736Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-28T12:35:34.979Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-28T12:35:40.255Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-28T12:36:53.295Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-28T12:36:55.169Z"
   },
   {
    "duration": 10305,
    "start_time": "2023-02-28T12:36:55.689Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
